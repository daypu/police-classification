{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from transformers import BertTokenizer, BertConfig, BertModel, Trainer, TrainingArguments, BertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size + 2, config.num_labels)  # 增加了2个特征\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, month=None, hour=None, labels=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output  # BERT模型的pooler_output\n",
    "        \n",
    "        # 将时间特征拼接到pooled_output中\n",
    "        time_features = torch.stack((month, hour), dim=1).float()  # 创建时间特征张量，假设 month 和 hour 的形状都是 [batch_size]\n",
    "        pooled_output = torch.cat((pooled_output, time_features), dim=1)  # 在最后一个维度上拼接\n",
    "        \n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        outputs = (logits,) + outputs[2:]  # 将 logits 与 BERT 模型的其他输出组合在一起\n",
    "        \n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold results:\n",
      "Major Label Accuracy: 0.7658227848101266\n",
      "Minor Label Accuracy: 0.6170886075949367\n",
      "Fold results:\n",
      "Major Label Accuracy: 0.8205128205128205\n",
      "Minor Label Accuracy: 0.717948717948718\n",
      "Fold results:\n",
      "Major Label Accuracy: 0.967948717948718\n",
      "Minor Label Accuracy: 0.9647435897435898\n",
      "Fold results:\n",
      "Major Label Accuracy: 0.9487179487179487\n",
      "Minor Label Accuracy: 0.907051282051282\n",
      "Fold results:\n",
      "Major Label Accuracy: 0.9483870967741935\n",
      "Minor Label Accuracy: 0.8935483870967742\n",
      "Fold results:\n",
      "Major Label Accuracy: 0.9006410256410257\n",
      "Minor Label Accuracy: 0.8814102564102564\n",
      "Fold results:\n",
      "Major Label Accuracy: 0.9391025641025641\n",
      "Minor Label Accuracy: 0.8878205128205128\n",
      "Fold results:\n",
      "Major Label Accuracy: 0.9551282051282052\n",
      "Minor Label Accuracy: 0.9134615384615384\n",
      "Fold results:\n",
      "Major Label Accuracy: 0.9519230769230769\n",
      "Minor Label Accuracy: 0.9391025641025641\n",
      "Fold results:\n",
      "Major Label Accuracy: 0.9775641025641025\n",
      "Minor Label Accuracy: 0.9294871794871795\n",
      "Average Major Label Accuracy: 0.917574834312278\n",
      "Average Minor Label Accuracy: 0.8651662635717351\n"
     ]
    }
   ],
   "source": [
    "# 加载BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载大类和小类编码器\n",
    "major_encoder = joblib.load('major_encoder.pkl')\n",
    "minor_encoder = joblib.load('minor_encoder.pkl')\n",
    "\n",
    "# 初始化变量\n",
    "num_major_labels = None\n",
    "num_minor_labels = None\n",
    "num_labels = None\n",
    "\n",
    "# 打开并读取文件内容\n",
    "with open('labels_info.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 解析文件内容并赋值给变量\n",
    "for line in lines:\n",
    "    if line.startswith(\"Number of major labels:\"):\n",
    "        num_major_labels = int(line.split(\": \")[1].strip())\n",
    "    elif line.startswith(\"Number of minor labels:\"):\n",
    "        num_minor_labels = int(line.split(\": \")[1].strip())\n",
    "    elif line.startswith(\"Total number of labels:\"):\n",
    "        num_labels = int(line.split(\": \")[1].strip())\n",
    "\n",
    "# 加载自定义模型权重\n",
    "config = BertConfig.from_pretrained('bert-base-chinese', num_labels=num_labels)\n",
    "model = CustomBertForSequenceClassification.from_pretrained('bert-base-chinese', config=config)  # 多标签分类，输出类别数量需适当调整\n",
    "model.load_state_dict(torch.load('model.pth'))  # 加载训练好的模型权重\n",
    "model.eval()\n",
    "\n",
    "# 读取CSV文件的前5行数据\n",
    "csv_file = \"data/data_cleaned_enhanced.csv\"  # 替换成你的CSV文件路径\n",
    "df = pd.read_csv(csv_file, header=0)  # 读取前5行数据\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # 提取日期和时间特征\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['time'] = pd.to_datetime(data['time'], format='%H:%M:%S').dt.time\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['hour'] = data['time'].apply(lambda x: x.hour)\n",
    "\n",
    "    # 对标签进行编码\n",
    "    data['major_label_encoded'] = major_encoder.transform(data['bjlbmc'])\n",
    "    data['minor_label_encoded'] = minor_encoder.transform(data['bjlxmc'])\n",
    "\n",
    "    return data\n",
    "\n",
    "# 执行推理\n",
    "def predict(input_ids, attention_mask, month, hour, true_major_labels, true_minor_labels):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, month=month, hour=hour)\n",
    "        logits = outputs[0]\n",
    "\n",
    "    major_preds = np.argmax(logits[:, :num_major_labels].cpu().numpy(), axis=1)\n",
    "    minor_preds = np.argmax(logits[:, num_major_labels:].cpu().numpy(), axis=1)\n",
    "\n",
    "    major_labels = major_encoder.inverse_transform(major_preds)\n",
    "    minor_labels = minor_encoder.inverse_transform(minor_preds)\n",
    "\n",
    "    # 计算准确率\n",
    "    major_accuracy = accuracy_score(true_major_labels, major_preds)\n",
    "    minor_accuracy = accuracy_score(true_minor_labels, minor_preds)\n",
    "\n",
    "    return major_labels, minor_labels, major_accuracy, minor_accuracy\n",
    "\n",
    "# 预处理数据\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# 将数据按照每4行分组\n",
    "n = 4\n",
    "groups = [df.iloc[i:i+n] for i in range(0, len(df), n)]\n",
    "\n",
    "# 将这些组转化为一个DataFrame列表\n",
    "group_dfs = [group.reset_index(drop=True) for group in groups]\n",
    "\n",
    "# 创建一个包含这些组的索引列表\n",
    "group_indices = list(range(len(group_dfs)))\n",
    "\n",
    "# 10折交叉验证\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "major_accuracies = []\n",
    "minor_accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(group_indices):\n",
    "    # 根据索引划分训练集和测试集\n",
    "    train_groups = [group_dfs[i] for i in train_index]\n",
    "    test_groups = [group_dfs[i] for i in test_index]\n",
    "\n",
    "    # 将这些组合并成训练集和测试集的DataFrame\n",
    "    train_df = pd.concat(train_groups).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_groups).reset_index(drop=True)\n",
    "\n",
    "    # 提取训练集和测试集的各列数据\n",
    "    train_texts = train_df['content']\n",
    "    test_texts = test_df['content']\n",
    "    train_major = train_df['major_label_encoded']\n",
    "    test_major = test_df['major_label_encoded']\n",
    "    train_minor = train_df['minor_label_encoded']\n",
    "    test_minor = test_df['minor_label_encoded']\n",
    "    train_month = train_df['month']\n",
    "    test_month = test_df['month']\n",
    "    train_hour = train_df['hour']\n",
    "    test_hour = test_df['hour']\n",
    "\n",
    "    # 文本处理，tokenize\n",
    "    tokenized_test = tokenizer(list(test_texts), padding='max_length', truncation=True, max_length=64, return_tensors='pt')\n",
    "\n",
    "    # 转换为张量\n",
    "    input_ids = tokenized_test['input_ids'].to(device)\n",
    "    attention_mask = tokenized_test['attention_mask'].to(device)\n",
    "    month = torch.tensor(test_month.values).to(device)\n",
    "    hour = torch.tensor(test_hour.values).to(device)\n",
    "\n",
    "    # 执行推理过程\n",
    "    major_labels, minor_labels, major_accuracy, minor_accuracy = predict(input_ids, attention_mask, month, hour, test_major.values, test_minor.values)\n",
    "\n",
    "    # 输出预测结果和准确率\n",
    "    print(f\"Fold results:\")\n",
    "    print(f\"Major Label Accuracy: {major_accuracy}\")\n",
    "    print(f\"Minor Label Accuracy: {minor_accuracy}\")\n",
    "\n",
    "    major_accuracies.append(major_accuracy)\n",
    "    minor_accuracies.append(minor_accuracy)\n",
    "\n",
    "# 输出平均准确率\n",
    "print(f\"Average Major Label Accuracy: {np.mean(major_accuracies)}\")\n",
    "print(f\"Average Minor Label Accuracy: {np.mean(minor_accuracies)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

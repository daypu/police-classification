{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/bjsj.csv\", engine='python', header=0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bjsj</th>\n",
       "      <th>bjnr</th>\n",
       "      <th>bjlbdm</th>\n",
       "      <th>bjlxdm</th>\n",
       "      <th>bjxldm</th>\n",
       "      <th>bjlbmc</th>\n",
       "      <th>bjlxmc</th>\n",
       "      <th>bjxlmc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-11 21:49:00.0</td>\n",
       "      <td>2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100120.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-11 21:43:25.0</td>\n",
       "      <td>2024年4月11日 21时43分22秒 郭女士( 139****6828 ) 报警：沙XX...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100199.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-11 21:16:36.0</td>\n",
       "      <td>2024年4月11日 21时16分35秒 牛女士( 151****7579 ，142329*...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100120.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-11 21:09:29.0</td>\n",
       "      <td>2024年4月11日 21时9分28秒 王先生( 151****8799、140111***...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100120.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-11 21:01:51.0</td>\n",
       "      <td>2024年4月11日 10时44分48秒 黄志明( 151****3088 、350524*...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100199.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bjsj                                               bjnr  \\\n",
       "0  2024-04-11 21:49:00.0  2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...   \n",
       "1  2024-04-11 21:43:25.0  2024年4月11日 21时43分22秒 郭女士( 139****6828 ) 报警：沙XX...   \n",
       "2  2024-04-11 21:16:36.0  2024年4月11日 21时16分35秒 牛女士( 151****7579 ，142329*...   \n",
       "3  2024-04-11 21:09:29.0  2024年4月11日 21时9分28秒 王先生( 151****8799、140111***...   \n",
       "4  2024-04-11 21:01:51.0  2024年4月11日 10时44分48秒 黄志明( 151****3088 、350524*...   \n",
       "\n",
       "   bjlbdm  bjlxdm    bjxldm bjlbmc bjlxmc  bjxlmc  \n",
       "0      10  100100  100120.0   刑事案件     盗窃     NaN  \n",
       "1      10  100100  100199.0   刑事案件     盗窃     NaN  \n",
       "2      10  100100  100120.0   刑事案件     盗窃     NaN  \n",
       "3      10  100100  100120.0   刑事案件     盗窃     NaN  \n",
       "4      10  100100  100199.0   刑事案件     盗窃     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bjsj</th>\n",
       "      <th>bjnr</th>\n",
       "      <th>bjlbdm</th>\n",
       "      <th>bjlxdm</th>\n",
       "      <th>bjxldm</th>\n",
       "      <th>bjlbmc</th>\n",
       "      <th>bjlxmc</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-11 21:49:00.0</td>\n",
       "      <td>2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100120.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>21:49:00</td>\n",
       "      <td>XX村北XX街，女朋友放在口袋内一部价值9000元苹果手机被盗。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-11 21:43:25.0</td>\n",
       "      <td>2024年4月11日 21时43分22秒 郭女士( 139****6828 ) 报警：沙XX...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100199.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>21:43:25</td>\n",
       "      <td>沙XX街天和XX小区6号楼3单元2802，现房门锁子打不开，门锁上有被砸痕迹，恐家内进入小偷...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-11 21:16:36.0</td>\n",
       "      <td>2024年4月11日 21时16分35秒 牛女士( 151****7579 ，142329*...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100120.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>21:16:36</td>\n",
       "      <td>XX街寇XX路口往北200米路西处，放在口袋内一部价值1000余元的VIVO手机被盗。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-11 21:09:29.0</td>\n",
       "      <td>2024年4月11日 21时9分28秒 王先生( 151****8799、140111***...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100120.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>21:09:29</td>\n",
       "      <td>亲XX街王府井百货门口，放在衣服口袋内价值17000余元的华为手机被盗。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-11 21:01:51.0</td>\n",
       "      <td>2024年4月11日 10时44分48秒 黄志明( 151****3088 、350524*...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100199.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>21:01:51</td>\n",
       "      <td>昨天，将车停放在南中环当代城摩马门口，现发现三元催化被盗，价值35000元。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bjsj                                               bjnr  \\\n",
       "0  2024-04-11 21:49:00.0  2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...   \n",
       "1  2024-04-11 21:43:25.0  2024年4月11日 21时43分22秒 郭女士( 139****6828 ) 报警：沙XX...   \n",
       "2  2024-04-11 21:16:36.0  2024年4月11日 21时16分35秒 牛女士( 151****7579 ，142329*...   \n",
       "3  2024-04-11 21:09:29.0  2024年4月11日 21时9分28秒 王先生( 151****8799、140111***...   \n",
       "4  2024-04-11 21:01:51.0  2024年4月11日 10时44分48秒 黄志明( 151****3088 、350524*...   \n",
       "\n",
       "   bjlbdm  bjlxdm    bjxldm bjlbmc bjlxmc       date      time  \\\n",
       "0      10  100100  100120.0   刑事案件     盗窃 2024-04-11  21:49:00   \n",
       "1      10  100100  100199.0   刑事案件     盗窃 2024-04-11  21:43:25   \n",
       "2      10  100100  100120.0   刑事案件     盗窃 2024-04-11  21:16:36   \n",
       "3      10  100100  100120.0   刑事案件     盗窃 2024-04-11  21:09:29   \n",
       "4      10  100100  100199.0   刑事案件     盗窃 2024-04-11  21:01:51   \n",
       "\n",
       "                                             content  \n",
       "0                   XX村北XX街，女朋友放在口袋内一部价值9000元苹果手机被盗。  \n",
       "1  沙XX街天和XX小区6号楼3单元2802，现房门锁子打不开，门锁上有被砸痕迹，恐家内进入小偷...  \n",
       "2        XX街寇XX路口往北200米路西处，放在口袋内一部价值1000余元的VIVO手机被盗。  \n",
       "3               亲XX街王府井百货门口，放在衣服口袋内价值17000余元的华为手机被盗。  \n",
       "4             昨天，将车停放在南中环当代城摩马门口，现发现三元催化被盗，价值35000元。  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(dataset.columns) > 7:\n",
    "    dataset = dataset.drop(dataset.columns[7], axis=1)\n",
    "\n",
    "# 判断是否已存在 'date' 和 'time' 列，避免重复执行\n",
    "if 'date' not in dataset.columns and 'time' not in dataset.columns:\n",
    "    # 拆分“bjsj”列成“日期”和“时间”两列，并转换为相应格式\n",
    "    dataset['date'] = pd.to_datetime(dataset['bjsj'].str.split().str[0], format='%Y-%m-%d')\n",
    "    dataset['time'] = pd.to_datetime(dataset['bjsj'].str.split().str[1], format='%H:%M:%S.%f').dt.time\n",
    "\n",
    "\n",
    "\n",
    "def extract_info(text):\n",
    "    # 使用正则表达式匹配关键词后面的内容作为报警内容\n",
    "    match = re.search(r'(?:报警：|称|在)(.*)', text)\n",
    "    if match:\n",
    "        content = match.group(1)\n",
    "        return content.strip()  # 去除首尾空格\n",
    "    else:\n",
    "        return text.strip()  # 如果没有匹配到关键词，则整行内容作为报警内容\n",
    "\n",
    "# 判断是否已存在 'content' 列，避免重复执行\n",
    "if 'content' not in dataset.columns:\n",
    "    # 提取报警内容\n",
    "    dataset['content'] = dataset['bjnr'].apply(extract_info)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 924 entries, 0 to 923\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   bjsj     924 non-null    object        \n",
      " 1   bjnr     924 non-null    object        \n",
      " 2   bjlbdm   924 non-null    int64         \n",
      " 3   bjlxdm   924 non-null    int64         \n",
      " 4   bjxldm   527 non-null    float64       \n",
      " 5   bjlbmc   924 non-null    object        \n",
      " 6   bjlxmc   924 non-null    object        \n",
      " 7   date     924 non-null    datetime64[ns]\n",
      " 8   time     924 non-null    object        \n",
      " 9   content  924 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(6)\n",
      "memory usage: 72.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除重复列\n",
    "dataset = dataset.drop_duplicates(subset=dataset.columns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/28/dhnkpq7x2ng78vx80gq2gwmc0000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simbert不能正常使用，除非你安装：bert4keras、tensorflow ，为了安装快捷，没有默认安装.... No module named 'bert4keras'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.297 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load :/Users/daypu/anaconda3/envs/pytorch/lib/python3.10/site-packages/nlpcda/data/同义词.txt done\n"
     ]
    }
   ],
   "source": [
    "# 对文本进行增强\n",
    "from nlpcda import Similarword, RandomDeleteChar\n",
    "\n",
    "# 假设 dataset 是你的数据集 DataFrame\n",
    "input_csv = dataset\n",
    "\n",
    "# 初始化增强方法\n",
    "smw = Similarword(create_num=2, change_rate=0.5)\n",
    "rdc = RandomDeleteChar(create_num=2, change_rate=0.3)\n",
    "\n",
    "# 定义函数来对文本进行增强\n",
    "def augment_text(text):\n",
    "    augmented_texts = []\n",
    "    \n",
    "    # 同义词替换增强\n",
    "    for _ in range(2):  # 创建两个增强文本\n",
    "        augmented_text_list = smw.replace(text)\n",
    "        if len(augmented_text_list) > 1:\n",
    "            augmented_text = augmented_text_list[1]  # 取第二个增强后的文本\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    # 随机字删除增强\n",
    "    for _ in range(2):  # 创建两个增强文本\n",
    "        augmented_text_list = rdc.replace(text)\n",
    "        if len(augmented_text_list) > 1:\n",
    "            augmented_text = augmented_text_list[1]  # 取第二个增强后的文本\n",
    "            augmented_texts.append(augmented_text)\n",
    "    \n",
    "    return augmented_texts\n",
    "\n",
    "# 对每行的 \"content\" 列进行增强，并保存增强后的数据\n",
    "augmented_data = []\n",
    "\n",
    "for index, row in input_csv.iterrows():\n",
    "    original_content = row['content']\n",
    "    augmented_contents = augment_text(original_content)\n",
    "    \n",
    "    for augmented_content in augmented_contents:\n",
    "        new_row = row.copy()\n",
    "        new_row['content'] = augmented_content\n",
    "        augmented_data.append(new_row)\n",
    "\n",
    "# 将增强后的数据转换为DataFrame，并保存为新的CSV文件\n",
    "augmented_df = pd.DataFrame(augmented_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3122 entries, 0 to 923\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   bjsj     3122 non-null   object        \n",
      " 1   bjnr     3122 non-null   object        \n",
      " 2   bjlbdm   3122 non-null   int64         \n",
      " 3   bjlxdm   3122 non-null   int64         \n",
      " 4   bjxldm   1728 non-null   float64       \n",
      " 5   bjlbmc   3122 non-null   object        \n",
      " 6   bjlxmc   3122 non-null   object        \n",
      " 7   date     3122 non-null   datetime64[ns]\n",
      " 8   time     3122 non-null   object        \n",
      " 9   content  3122 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(6)\n",
      "memory usage: 268.3+ KB\n"
     ]
    }
   ],
   "source": [
    "augmented_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bjlbmc\n",
       "治安警情      1078\n",
       "刑事案件       484\n",
       "交通警情       472\n",
       "群众求助       352\n",
       "社会联动       192\n",
       "消防救援       164\n",
       "举报线索       156\n",
       "群体事件       154\n",
       "其他报警类别      42\n",
       "投诉监督        24\n",
       "灾害事故         4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df[\"bjlbmc\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bjlxmc\n",
       "诈骗             148\n",
       "敲诈勒索           148\n",
       "盗窃             144\n",
       "打架斗殴            80\n",
       "其它举报线索          80\n",
       "环保执法            80\n",
       "其它群众求助          80\n",
       "其它交通管理          80\n",
       "交通违法            80\n",
       "交通事故            80\n",
       "其它治安警情          80\n",
       "交通设施            80\n",
       "聚众上访            78\n",
       "其它刑警情           76\n",
       "提供线索            76\n",
       "其它群体警情          76\n",
       "色情淫秽            74\n",
       "恐吓              72\n",
       "失物求助            72\n",
       "火灾              72\n",
       "交通逃逸            72\n",
       "其它消防救援          72\n",
       "妨碍公务            70\n",
       "扰乱秩序            70\n",
       "治安纠纷            66\n",
       "抢夺              64\n",
       "其它社会联动          64\n",
       "家庭暴力            64\n",
       "强奸              64\n",
       "交通秩序            60\n",
       "抢劫              60\n",
       "赌博              60\n",
       "自杀求助            60\n",
       "故意毁坏公私财物        58\n",
       "走失求助            56\n",
       "水、电、气、热险情求助     52\n",
       "侵犯人身权利          48\n",
       "其它报警类型          42\n",
       "安全生产监督          32\n",
       "非法侵入他人住宅        32\n",
       "制贩、使用假币         20\n",
       "开锁求助            20\n",
       "抢险救援            20\n",
       "交通保障            20\n",
       "群众投诉            16\n",
       "伤害              12\n",
       "伪造票证、凭证         12\n",
       "贩毒              12\n",
       "绑架               8\n",
       "坠楼求助             8\n",
       "纵火               8\n",
       "虐待               8\n",
       "其他投诉监督           8\n",
       " 林水管理            4\n",
       "文广管理             4\n",
       "水气热抢修            4\n",
       "食品药品管理           4\n",
       "其它灾害事故           4\n",
       "非法拘禁             4\n",
       "危急病人求助           4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df[\"bjlxmc\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存修改后的CSV文件\n",
    "augmented_df.to_csv('data/data_cleaned_enhanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import types\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import BertTokenizer, BertConfig, BertModel, Trainer, TrainingArguments\n",
    "from transformers import AdamW, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "\n",
    "df = pd.read_csv(\"data_cleaned_enhanced.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bjsj</th>\n",
       "      <th>bjnr</th>\n",
       "      <th>bjlbdm</th>\n",
       "      <th>bjlxdm</th>\n",
       "      <th>bjxldm</th>\n",
       "      <th>bjlbmc</th>\n",
       "      <th>bjlxmc</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-11 21:49:00.0</td>\n",
       "      <td>2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100120.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>21:49:00</td>\n",
       "      <td>XX村北XX街，女朋友放在口袋内一部价9000元苹果手机被盗。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-11 21:49:00.0</td>\n",
       "      <td>2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100120.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>21:49:00</td>\n",
       "      <td>XX村北XX街，女朋友雄居口袋内一部价9000元苹手机被盗。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-11 21:49:00.0</td>\n",
       "      <td>2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100120.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>21:49:00</td>\n",
       "      <td>XX村北XX，女朋友放在口袋一部价值9000元苹果手机被盗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-11 21:49:00.0</td>\n",
       "      <td>2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100120.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>21:49:00</td>\n",
       "      <td>XX村北XX街女朋友放在口袋内一部价值9000元苹果手机被盗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-11 21:43:25.0</td>\n",
       "      <td>2024年4月11日 21时43分22秒 郭女士( 139****6828 ) 报警：沙XX...</td>\n",
       "      <td>10</td>\n",
       "      <td>100100</td>\n",
       "      <td>100199.0</td>\n",
       "      <td>刑事案件</td>\n",
       "      <td>盗窃</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>21:43:25</td>\n",
       "      <td>沙XX街天和XX小区6号楼3单元2802，现房门锁子打不开，门锁上有被砸痕迹，恐家内进入鸡鸣...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bjsj                                               bjnr  \\\n",
       "0  2024-04-11 21:49:00.0  2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...   \n",
       "1  2024-04-11 21:49:00.0  2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...   \n",
       "2  2024-04-11 21:49:00.0  2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...   \n",
       "3  2024-04-11 21:49:00.0  2024年4月11日 21时48分55秒 薛一铭( 180****5228 ，142427*...   \n",
       "4  2024-04-11 21:43:25.0  2024年4月11日 21时43分22秒 郭女士( 139****6828 ) 报警：沙XX...   \n",
       "\n",
       "   bjlbdm  bjlxdm    bjxldm bjlbmc bjlxmc        date      time  \\\n",
       "0      10  100100  100120.0   刑事案件     盗窃  2024-04-11  21:49:00   \n",
       "1      10  100100  100120.0   刑事案件     盗窃  2024-04-11  21:49:00   \n",
       "2      10  100100  100120.0   刑事案件     盗窃  2024-04-11  21:49:00   \n",
       "3      10  100100  100120.0   刑事案件     盗窃  2024-04-11  21:49:00   \n",
       "4      10  100100  100199.0   刑事案件     盗窃  2024-04-11  21:43:25   \n",
       "\n",
       "                                             content  \n",
       "0                    XX村北XX街，女朋友放在口袋内一部价9000元苹果手机被盗。  \n",
       "1                     XX村北XX街，女朋友雄居口袋内一部价9000元苹手机被盗。  \n",
       "2                      XX村北XX，女朋友放在口袋一部价值9000元苹果手机被盗  \n",
       "3                     XX村北XX街女朋友放在口袋内一部价值9000元苹果手机被盗  \n",
       "4  沙XX街天和XX小区6号楼3单元2802，现房门锁子打不开，门锁上有被砸痕迹，恐家内进入鸡鸣...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_vocab = df[\"bjlbmc\"].unique()\n",
    "minor_vocab = df[\"bjlxmc\"].unique()\n",
    "\n",
    "# 创建LabelEncoder对象\n",
    "major_encoder = LabelEncoder()\n",
    "minor_encoder = LabelEncoder()\n",
    "\n",
    "# 对标签进行编码\n",
    "df['major_label_encoded'] = major_encoder.fit_transform(df['bjlbmc'])\n",
    "df['minor_label_encoded'] = minor_encoder.fit_transform(df['bjlxmc'])\n",
    "\n",
    "# 计算主要标签和次要标签的类别数量\n",
    "num_major_labels = df['bjlbmc'].nunique() # 大类\n",
    "num_minor_labels = df['bjlxmc'].nunique() # 小类\n",
    "\n",
    "# 设置 num_labels 为主要标签和次要标签类别数量之和\n",
    "num_labels = num_major_labels + num_minor_labels\n",
    "# 将各类标签保存到文本文件中\n",
    "with open('labels_info.txt', 'w') as f:\n",
    "    f.write(f\"Number of major labels: {num_major_labels}\\n\")\n",
    "    f.write(f\"Number of minor labels: {num_minor_labels}\\n\")\n",
    "    f.write(f\"Total number of labels: {num_labels}\\n\")\n",
    "\n",
    "\n",
    "import joblib\n",
    "# 保存 LabelEncoder 对象\n",
    "joblib.dump(major_encoder, 'major_encoder.pkl')\n",
    "joblib.dump(minor_encoder, 'minor_encoder.pkl')\n",
    "\n",
    "# 提取日期和时间特征\n",
    "df['month'] = pd.to_datetime(df['date']).dt.month\n",
    "df['hour'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "train_texts, test_texts, train_major, test_major, train_minor, test_minor, train_month, test_month, train_hour, test_hour = train_test_split(\n",
    "    df['content'], df['major_label_encoded'], df['minor_label_encoded'], df['month'], df['hour'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练集和测试集的Dataset对象\n",
    "train_dataset = Dataset.from_pandas(pd.DataFrame({'text': train_texts, 'major_label': train_major, 'minor_label': train_minor, 'month': train_month, 'hour': train_hour}))\n",
    "test_dataset = Dataset.from_pandas(pd.DataFrame({'text': test_texts, 'major_label': test_major, 'minor_label': test_minor, 'month': test_month, 'hour': test_hour}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abe8f1256924c5a8435536170fea229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2497 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcc8f5e40164d8db5ebb7e74b57452c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/625 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703f6d7640364944adc0e5afbb3112be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2497 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8db52079f045c487e2bda2827e50ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/625 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 对文本进行tokenize，并转换为BERT的输入格式\n",
    "def tokenize_texts(example):\n",
    "    encoding = tokenizer(example['text'], padding='max_length', truncation=True, max_length=64)\n",
    "    encoding['month'] = example['month']\n",
    "    encoding['hour'] = example['hour']\n",
    "    # encoding['minute'] = example['minute']\n",
    "    return encoding\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_texts, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_texts, batched=True)\n",
    "\n",
    "# 转换标签为张量类型\n",
    "def convert_labels(example):\n",
    "    example['major_label'] = torch.tensor(example['major_label'])\n",
    "    example['minor_label'] = torch.tensor(example['minor_label'])\n",
    "    example['month'] = torch.tensor(example['month'])\n",
    "    example['hour'] = torch.tensor(example['hour'])\n",
    "    # example['minute'] = torch.tensor(example['minute'])\n",
    "    return example\n",
    "\n",
    "train_dataset = train_dataset.map(convert_labels)\n",
    "test_dataset = test_dataset.map(convert_labels)\n",
    "\n",
    "# 设置返回张量格式\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'major_label', 'minor_label', 'month', 'hour'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'major_label', 'minor_label', 'month', 'hour'])\n",
    "\n",
    "# 将数据集转换为 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBertForSequenceClassification(BertForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size + 2, config.num_labels)  # 增加了2个特征\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, month=None, hour=None, labels=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output  # BERT模型的pooler_output\n",
    "        \n",
    "        # 将时间特征拼接到pooled_output中\n",
    "        time_features = torch.stack((month, hour), dim=1).float()  # 创建时间特征张量，假设 month 和 hour 的形状都是 [batch_size]\n",
    "        pooled_output = torch.cat((pooled_output, time_features), dim=1)  # 在最后一个维度上拼接\n",
    "        \n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        outputs = (logits,) + outputs[2:]  # 将 logits 与 BERT 模型的其他输出组合在一起\n",
    "        \n",
    "        if labels is not None:\n",
    "            if self.num_labels == 1:\n",
    "                loss_fct = nn.MSELoss()\n",
    "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
    "            else:\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CustomBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomBertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=770, out_features=71, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载BERT模型和训练参数\n",
    "config = BertConfig.from_pretrained('bert-base-chinese', num_labels=num_labels)\n",
    "\n",
    "model = CustomBertForSequenceClassification.from_pretrained('bert-base-chinese', config=config)  # 多标签分类，输出类别数量需适当调整\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daypu/anaconda3/envs/pytorch/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/10: 100%|██████████| 313/313 [02:49<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 4.024419457386858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 79/79 [00:11<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Test Loss: 2.4272379528118084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 313/313 [02:44<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 1.6552274932686133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 79/79 [00:11<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Test Loss: 1.2269477840465834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 313/313 [02:47<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.8663716019628147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 79/79 [00:12<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Test Loss: 0.8204853678994541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 313/313 [02:46<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.5103789413460909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 79/79 [00:12<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Test Loss: 0.47746341067213044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 313/313 [02:51<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.2414186061404574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 79/79 [00:14<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Test Loss: 0.41155912477193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 313/313 [02:49<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.15522024259209252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 79/79 [00:12<00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Test Loss: 0.48473890290796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 313/313 [02:47<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.3149445329468471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 79/79 [00:12<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Test Loss: 0.5450129973454566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 313/313 [02:49<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.20756113719635497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 79/79 [00:13<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Test Loss: 0.2434947330598967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 313/313 [02:52<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.09833763912915232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 79/79 [00:12<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Test Loss: 0.0980232213918544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 313/313 [02:48<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.05403644794199509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 79/79 [00:12<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Test Loss: 0.23954555055692414\n"
     ]
    }
   ],
   "source": [
    "# 定义优化器和损失函数\n",
    "optimizer = AdamW(model.parameters(), lr=6e-5, weight_decay=2e-3)\n",
    "criterion = nn.CrossEntropyLoss()  # 适用于多分类任务，根据实际情况可能需要调整损失函数\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练模式\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        major_labels = batch['major_label'].to(device)\n",
    "        minor_labels = batch['minor_label'].to(device)\n",
    "        month = batch['month'].to(device)\n",
    "        hour = batch['hour'].to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, month=month, hour=hour)\n",
    "        logits = outputs[0]  # outputs包含损失和logits，第一个元素是logits\n",
    "\n",
    "        # 计算损失\n",
    "        loss_major = criterion(logits[:, :num_major_labels], major_labels)\n",
    "        loss_minor = criterion(logits[:, num_major_labels:], minor_labels)\n",
    "        loss = loss_major + loss_minor\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # 打印每个epoch的训练损失\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss / len(train_loader)}\")\n",
    "\n",
    "    # 评估模式\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        major_labels = batch['major_label'].to(device)\n",
    "        minor_labels = batch['minor_label'].to(device)\n",
    "        month = batch['month'].to(device)\n",
    "        hour = batch['hour'].to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, month=month, hour=hour)\n",
    "            logits = outputs[0]  # outputs包含损失和logits，第一个元素是logits\n",
    "\n",
    "            # 计算损失\n",
    "            loss_major = criterion(logits[:, :num_major_labels], major_labels)\n",
    "            loss_minor = criterion(logits[:, num_major_labels:], minor_labels)\n",
    "            loss = loss_major + loss_minor\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    # 打印每个epoch的评估损失\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Test Loss: {test_loss / len(test_loader)}\")\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
